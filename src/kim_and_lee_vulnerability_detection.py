import os
import logging
import timeit
import json
import re
import tldextract

import pdg_js.utility_df as utility_df

from extension_communication import build_extension_pdg
import utility
from pdg_js.node import Node, Identifier
from vulnerability_detection import store_analysis_results, default

PRINT_DEBUG = utility.PRINT_DEBUG


def analyze_extension(cs_path, bp_path, json_analysis=None, pdg=False, chrome=True, war=False,
                      json_messages=None, json_apis='permissions', manifest_path=None, return_result=True,
                      store_result_as_json_file=True, print_result=False):
    # Note pdg=True if the PDGs have already been generated!

    res_dict = dict()
    extension_path = res_dict['extension'] = os.path.dirname(cs_path)
    benchmarks = res_dict['benchmarks'] = dict()
    messages_dict = dict()

    if manifest_path is None:
        manifest_path = os.path.join(extension_path, 'manifest.json')

    # cf. check_permissions.py:permission_check() and check_permissions.py:permission_check_v3():
    try:
        manifest = json.load(open(manifest_path))
        res_dict['manifest_version'] = manifest['manifest_version']
        if 'content_scripts' in manifest:
            urls = [cs['matches'] for cs in manifest['content_scripts']]
            res_dict['content_script_injected_into'] = [x for xs in urls for x in xs]  # flatten list of lists of URLs
        else:
            res_dict['content_script_injected_into'] = []
    except FileNotFoundError:
        logging.critical('No manifest file found in %s', manifest_path)

    pdg_cs, pdg_bp = build_extension_pdg(cs_path=cs_path, bp_path=bp_path, benchmarks=benchmarks,
                                         pdg=pdg, chrome=chrome, messages_dict=messages_dict)

    logging.info('Finished to link CS with BP using the message passing APIs')

    no_added_df_edges_cs = add_missing_data_flow_edges(pdg_cs)
    print(f"{no_added_df_edges_cs} missing data flows edges added to CS PDG")
    no_added_df_edges_bp = add_missing_data_flow_edges(pdg_bp)
    print(f"{no_added_df_edges_bp} missing data flows edges added to BP PDG")

    if os.environ.get('PRINT_PDGS') == "yes":
        print()
        print(f"PDG (CS):\n{pdg_cs}")  # <pdg_js.node.Node object>
        print()
        print(f"PDG (BP):\n{pdg_bp}")
        print()

    res_dict["bp"] = dict()
    bp_exfiltration_dangers = res_dict["bp"]['exfiltration_dangers'] = []
    bp_infiltration_dangers = res_dict["bp"]['infiltration_dangers'] = []
    if os.environ.get('INCLUDE_31_VIOLATIONS_WITHOUT_PRIVILEGED_API_ACCESS') == "yes":
        bp_31_violations_without_sensitive_api_access = res_dict["bp"]['31_violations_without_sensitive_api_access'] = []

    res_dict["cs"] = dict()
    cs_exfiltration_dangers = res_dict["cs"]['exfiltration_dangers'] = []
    cs_infiltration_dangers = res_dict["cs"]['infiltration_dangers'] = []

    try:
        with utility_df.Timeout(600):  # Tries to analyze an extension within 10 minutes
            detect_41_31_vuln_in_bp(pdg_bp=pdg_bp, results=bp_exfiltration_dangers, benchmarks=benchmarks, uxss=False)
            #detect_41_31_vuln_in_bp(pdg_bp=pdg_bp, res_dict=bp_infiltration_dict, uxss=True) # ToDo
            if os.environ.get('INCLUDE_31_VIOLATIONS_WITHOUT_PRIVILEGED_API_ACCESS') == "yes":
                detect_31_vuln_in_bp(pdg_bp=pdg_bp,
                                     results=bp_31_violations_without_sensitive_api_access,
                                     benchmarks=benchmarks)

    except utility_df.Timeout.Timeout:
        logging.exception('Analyzing the extension timed out for %s %s', cs_path, bp_path)
        if 'crashes' not in benchmarks:
            benchmarks['crashes'] = []
        benchmarks['crashes'].append('extension-analysis-timeout')

    if print_result or PRINT_DEBUG:
        print(json.dumps(res_dict, indent=4, sort_keys=False, default=default, skipkeys=True))
    if store_result_as_json_file:
        store_analysis_results(extension_path, json_analysis, json_messages,
                               res_dict, messages_dict, outfile_name="analysis_renderer_attacker.json")
    if return_result:
        return res_dict


def get_all_identifiers(node):  # ToDo: move to Node class!
    """
    Returns a list of all the Identifiers occurring in the given PDG subtree.
    """
    if node.name == "Identifier":
        return [node]
    else:
        result = []
        for child in node.children:
            result.extend(get_all_identifiers(child))
        return result


def add_missing_data_flow_edges(pdg):  # ToDo: add data flow edges between function calls(!!!) # ToDo: add dataflow edge from "x" to "x.y" ? # ToDo: handle flows like: "url = url.replace(...)"
    """
    Sadly, in the PDGs generated by DoubleX, some data flow edges that we need are missing.
    This function adds those missing data flow edges to the given PDG, e.g. those from y to x in a "x=y" assignment
    expression (including those cases where the "y" on the RHS is part of a more complex expression: "x=foo(y)").

    Parameters:
        pdg: the PDG (Program Dependence Graph), generated by DoubleX, to add the missing data flow edges to

    Returns:
        the number of data flow edges added to the given PDG, as an integer
    """

    # VariableDeclarator: let x=y, var x=y, const x=y

    # interface VariableDeclaration {
    #     declarations: VariableDeclarator[];
    #     kind: 'var' | 'const' | 'let';
    # }

    # interface VariableDeclarator {
    #     id: Identifier | BindingPattern;
    #     init: Expression | null;
    # }

    # type BindingPattern = ArrayPattern | ObjectPattern;

    # => Ignore VariableDeclarators like "let foo;" that have no right-hand-side!

    # AssignmentExpression: x=y

    # interface AssignmentExpression {
    #     operator: '=' | '*=' | '**=' | '/=' | '%=' | '+=' | '-=' | '<<=' | '>>=' | '>>>=' | '&=' | '^=' | '|=';
    #     left: Expression;
    #     right: Expression;
    # }

    # ==> Handle "Destructuring Assignments" like:
    #     "let [a, b] = [x, y];"             -> should create a flow from "x" to "a" and another one from "y" to "b"
    #     "const { a: a1, b: b1 } = obj;"    -> should create a flow from "obj" to "a1" and from "obj" to "b1"
    #       -> https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Destructuring_assignment

    # ==> Handle declarations/assignments to arbitrary expressions like:
    #     "let first_cookie = cookies[0];"     -> should create a flow from "cookies" to "first_cookie"
    #     "let first_cookie = cookies[1+2+3];" -> should create a flow from "cookies" to "first_cookie"
    #     "let x = y.z;"                       -> should create a flow from "y" to "x"
    #       -> https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Property_accessors
    #     "let first_cookie = JSON.stringify(cookies[0]);"    -> should create a flow from "cookies" to "first_cookie"

    # Example PDG subtrees:

    # ***** "let cookies2 = cookies;" or "var cookies2 = cookies;" or "const cookies2 = cookies;": *****
    # [1] [VariableDeclaration] (1 child)
    #     [2] [VariableDeclarator] (2 children)
    #         [3] [Identifier:"cookies2"] (0 children)
    #         [4] [Identifier:"cookies"] (0 children)

    # ***** "let cookies;": *****
    # [1] [VariableDeclaration] (1 child)
    #     [2] [VariableDeclarator] (1 child)
    #         [3] [Identifier:"cookies"] (0 children)

    # ***** "cookies2 = cookies;": *****
    # [1] [ExpressionStatement] (1 child)
    #     [2] [AssignmentExpression] (2 children)
    #         [3] [Identifier:"cookies2"] (0 children)
    #         [4] [Identifier:"cookies"] (0 children)

    # ***** "let [cookies2, forty_two] = [cookies, 42];": *****
    # [1] [VariableDeclaration] (1 child)
    #     [2] [VariableDeclarator] (2 children)
    #         [3] [ArrayPattern] (2 children)
    #             [4] [Identifier:"cookies2"] (0 children)
    #             [5] [Identifier:"forty_two"] (0 children)
    #         [6] [ArrayExpression] (2 children)
    #             [7] [Identifier:"cookies"] (0 children)
    #             [8] [Literal:"42"] (0 children)

    # Note that "let [four, five] = [4,5,6];" works as well.
    # "let [six, seven, eight] = [6,7];" works too, creating a variable "eight" that is undefined.
    # "[six, seven, eight] = [6,7];" sets the variable "eight" to undefined (or creating it).

    # ***** "const { a: cookies2, b: forty_two } = {a:cookies, b:42};": *****
    # [1] [VariableDeclaration] (1 child)
    #     [2] [VariableDeclarator] (2 children)
    #         [3] [ObjectPattern] (2 children)
    #             [4] [Property] (2 children)
    #                 [5] [Identifier:"a"] (0 children)
    #                 [6] [Identifier:"cookies2"] (0 children)
    #             [7] [Property] (2 children)
    #                 [8] [Identifier:"b"] (0 children)
    #                 [9] [Identifier:"forty_two"] (0 children)
    #         [10] [ObjectExpression] (2 children)
    #             [11] [Property] (2 children)
    #                 [12] [Identifier:"a"] (0 children)
    #                 [13] [Identifier:"cookies"] (0 children)
    #             [14] [Property] (2 children)
    #                 [15] [Identifier:"b"] (0 children)
    #                 [16] [Literal:"42"] (0 children)

    data_flow_edges_added = 0

    if (pdg.name == "VariableDeclarator" or pdg.name == "AssignmentExpression") and len(pdg.children) > 1:
        lhs = pdg.children[0]
        rhs = pdg.children[1]

        if lhs.name == "Identifier":  # "let cookies2 = cookies;" or "var cookies2 = cookies;" or "const cookies2 = cookies;" or "cookies2 = cookies;"
            for identifier in get_all_identifiers(rhs):  # For each identifier in the right-hand side...:
                # ...add a data flow edge *from* that identifier *to* the left-hand side:
                identifier.set_data_dependency(lhs)  # includes call: identifier.data_dep_children.append(extremity=lhs)
                data_flow_edges_added += 1

        elif lhs.name == "MemberExpression":
            # "x.y = z;", or, equivalently(!), "x[y] = z;" (both of these generate the same tree!):
            #     [1] [AssignmentExpression:"="] (2 children)
            # 			[2] [MemberExpression] (2 children)
            # 				[3] [Identifier:"x"] (0 children)
            # 				[4] [Identifier:"y"] (0 children)
            # 			[5] [Identifier:"z"] (0 children)
            #
            # Note that "x.y.z = w;", "x[y].z = w;", "x.y[z] = w;" and "x[y][z] = w;" also all generate the same nested tree structure:
            #     [1] [AssignmentExpression:"="] (2 children)
            # 			[2] [MemberExpression] (2 children)
            # 				[3] [MemberExpression] (2 children)
            # 					[4] [Identifier:"x"] (0 children)
            # 					[5] [Identifier:"y"] (0 children)
            # 				[6] [Identifier:"z"] (0 children)
            # 			[7] [Identifier:"w"] (0 children)
            leftmost_identifier = lhs.children[0]
            while leftmost_identifier.name == "MemberExpression":
                leftmost_identifier = leftmost_identifier.children[0]

            if leftmost_identifier.name == "Identifier":  # could also be a "ThisExpression" but we're not handling that for now!
                # cf. if-case above:
                for identifier in get_all_identifiers(rhs):  # For each identifier in the right-hand side...:
                    # ...add a data flow edge *from* that identifier *to* the leftmost identifier of the left-hand side:
                    identifier.set_data_dependency(leftmost_identifier)  # includes call: identifier.data_dep_children.append(extremity=lhs)
                    data_flow_edges_added += 1

        elif lhs.name == "ArrayPattern" and rhs.name == "ArrayExpression":  # "let [cookies2, forty_two] = [cookies, 42];" (the "let" being optional)
            for i in range(min(len(lhs.children), len(rhs.children))):
                for identifier in get_all_identifiers(rhs.children[i]):
                    identifier.set_data_dependency(lhs.children[i])
                    data_flow_edges_added += 1

        elif lhs.name == "ObjectPattern" and rhs.name == "ObjectExpression":  # "const { a: cookies2, b: forty_two } = {a:cookies, b:42};" (the "const" is optional, note however that parentheses around the assignment will be required instead then!)
            # Note that, unlike in the example, the keys of the LHS and RHS might be in a different order!
            lhs_keys = [property_.children[0].attributes['name'] for property_ in lhs.children if property_.name == "Property" and property_.children[0].name == "Identifier"]
            rhs_keys = [property_.children[0].attributes['name'] for property_ in rhs.children if property_.name == "Property" and property_.children[0].name == "Identifier"]
            data_flow_keys = set.intersection(set(lhs_keys), set(rhs_keys))  # in the example: set("a", "b")
            for key in data_flow_keys:
                lhs_value = [property_.children[1] for property_ in lhs.children if property_.name == "Property" and len(property_.children) > 1 and property_.children[0].name == "Identifier" and property_.children[0].attributes['name'] == key][0]
                rhs_value = [property_.children[1] for property_ in rhs.children if property_.name == "Property" and len(property_.children) > 1 and property_.children[0].name == "Identifier" and property_.children[0].attributes['name'] == key][0]
                for identifier in get_all_identifiers(rhs_value):
                    identifier.set_data_dependency(lhs_value)
                    data_flow_edges_added += 1

        elif lhs.name == "ObjectPattern" and rhs.name == "Identifier":  # "({url} = sender);" or "({url:url} = sender);"
            # Note that both "({url} = sender);" and "({url:url} = sender);" result in the same PDG being generated:
            # [1] [AssignmentExpression:"="] (2 children)
            #     [2] [ObjectPattern] (1 child)
            #         [3] [Property] (2 children)
            #             [4] [Identifier:"url"] (0 children)
            #             [5] [Identifier:"url"] (0 children)
            #     [6] [Identifier:"sender"] (0 children)
            for lhs_identifier in get_all_identifiers(lhs):
                rhs.set_data_dependency(lhs_identifier)  # Note how both ends of the new data flow edge are Identifiers!
                data_flow_edges_added += 1

        else:
            print(f"[Warning] Unknown type of {pdg.name} (LHS: {lhs.__class__}/{lhs.name}; "
                  f"RHS: {rhs.__class__})/{rhs.name} found in {pdg.get_file()}, line {pdg.get_line()}"
                  f" - possible missed data flow(s)")

    return data_flow_edges_added + sum(add_missing_data_flow_edges(child) for child in pdg.children)


def get_all_cookie_identifiers(pdg):
    """
    Returns all "cookie" (or arbitrarily named) identifiers coming from a
    ```
    chrome.cookies.getAll({}, function(cookies) { /* ... */ });
    ```
    or
    ```
    chrome.cookies.getAll({}, (cookies) => { /* ... */ });
    ```
    call.
    All these identifiers potentially contain very sensitive cookie data and shall not get into a
    content-script-accessible sink w/o proper authentication of the content script's URL!
    """
    pattern =\
        Node("CallExpression")\
            .child(
                Node("MemberExpression")
                    .child(
                        Node("MemberExpression")
                            .child(Node.identifier("chrome"))  # ToDo: handle programmer aliasing chrome.cookies.getAll
                            .child(Node.identifier("cookies"))
                    )
                    .child(
                        Node.identifier("getAll")  # ToDo: handle chrome.cookies.get() as well!
                    )
            )

    if os.environ.get('PRINT_PDGS') == "yes":
        print(f"Cookie Pattern #1:\n{pattern}")

    result = []
    for pattern_match in pdg.find_pattern(pattern,
                                          match_identifier_names=True,
                                          match_literals=False,   # irrelevant in this case
                                          match_operators=False,  # irrelevant in this case
                                          allow_additional_children=True,
                                          allow_different_child_order=False):
        if pattern_match.has_child("FunctionExpression"):  # case 1: FunctionExpression:
            result.append(pattern_match.get_child("FunctionExpression").get_child("Identifier"))
        elif pattern_match.has_child("ArrowFunctionExpression"):  # case 2: ArrowFunctionExpression:
            result.append(pattern_match.get_child("ArrowFunctionExpression").get_child("Identifier"))
    return result


def get_all_sendResponse_sinks(pdg):
    """
    Returns all "sendResponse" (or arbitrarily named) identifiers coming from a
    ```
    chrome.runtime.onMessage.addListener(function (message, sender, sendResponse) { /* ... */ });
    ```
    or
    ```
    chrome.runtime.onMessage.addListener((message, sender, sendResponse) => { /* ... */ });
    ```
    call.
    All these identifiers describe content-script-accessible sinks!
    """
    pattern =\
        Node("CallExpression")\
            .child(
                Node("MemberExpression")
                    .child(
                        Node("MemberExpression")
                            .child(
                                Node("MemberExpression")
                                    .child(Node.identifier("chrome"))   # Note that the "chrome" is necessary, simply  # ToDo: handle programmer aliasing chrome.runtime.onMessage
                                    .child(Node.identifier("runtime"))  # calling "runtime.onMessage" doesn't work!
                            )
                            .child(Node.identifier("onMessage"))
                    )
                    .child(
                        Node.identifier("addListener")
                    )
            )
            #.child(
            #    Node("FunctionExpression") or Node("ArrowFunctionExpression")
            #)

    if os.environ.get('PRINT_PDGS') == "yes":
        print(f"SendResponse Pattern #1:\n{pattern}")

    result = []
    for pattern_match in pdg.find_pattern(pattern,
                                          match_identifier_names=True,
                                          match_literals=False,   # irrelevant in this case
                                          match_operators=False,  # irrelevant in this case
                                          allow_additional_children=True,
                                          allow_different_child_order=False):

        if pattern_match.has_child("FunctionExpression"):  # case 1: FunctionExpression:
            if len(pattern_match.get_child("FunctionExpression").children) >= 4:  # (msg, sndr, sendResponse, block)
                result.append(pattern_match.get_child("FunctionExpression").children[2])  # (msg, sndr, *sendResponse*)

        elif pattern_match.has_child("ArrowFunctionExpression"):  # case 2: ArrowFunctionExpression:
            if len(pattern_match.get_child("ArrowFunctionExpression").children) >= 4:  # (msg, sndr, sendResponse, block)
                result.append(pattern_match.get_child("ArrowFunctionExpression").children[2])  # (msg, sndr, *sendResponse*)

        # Note that instead of (message, sender, sendResponse), the programmer may leave out trailing parameters:
        # either (message, sender) or just (message).
        # In that case however, there exists no `sendResponse` sink which this function could return.
        # When the programmer added additional redundant parameters though, e.g., (msg, sndr, sendResponse, foo, block),
        # this doesn't matter.
        # Therefore, we check if the (Arrow)FunctionExpression has *at least* 4 children.
    return result


def get_all_message_listeners(pdg, resolve_function_references=True):
    """
    Returns all message listeners in the given PDG.
    More precisely:
    Returns for all `x` for all `chrome.runtime.onMessage.addListener(x)` calls.
    Those xs returned should usually be one of the following:
    * a FunctionExpression
    * an ArrowFunctionExpression
    * a FunctionDeclaration (if resolve_function_references=True, which is the default)
    * an Identifier (if resolve_function_references=False, or when resolving a function reference failed!)
    """
    pattern =\
        Node("CallExpression")\
            .child(
                Node("MemberExpression")
                    .child(
                        Node("MemberExpression")
                            .child(
                                Node("MemberExpression")
                                    .child(Node.identifier("chrome"))   # Note that the "chrome" is necessary, simply  # ToDo: handle programmer aliasing chrome.runtime.onMessage
                                    .child(Node.identifier("runtime"))  # calling "runtime.onMessage" doesn't work!
                            )
                            .child(Node.identifier("onMessage"))
                    )
                    .child(
                        Node.identifier("addListener")
                    )
            )

    if os.environ.get('PRINT_PDGS') == "yes":
        print(f"Get All Message Listeners Pattern #1:\n{pattern}")

    result = []
    for pattern_match in pdg.find_pattern(pattern,
                                          match_identifier_names=True,
                                          match_literals=False,   # irrelevant in this case
                                          match_operators=False,  # irrelevant in this case
                                          allow_additional_children=True,
                                          allow_different_child_order=False):

        if len(pattern_match.children) >= 2:
            x = pattern_match.children[1]  # the `x` in `chrome.runtime.onMessage.addListener(x)`

            # Resolve function references if parameter resolve_function_references=True:
            if x.name == "Identifier" and resolve_function_references:
                x_data_flow_parents = x.get_data_flow_parents()
                x_data_flow_parents =\
                    [df_parent for df_parent in x_data_flow_parents if df_parent.parent.name == "FunctionDeclaration"]
                if len(x_data_flow_parents) == 1:
                    result.append(x_data_flow_parents[0].get_parent("FunctionDeclaration"))
                elif len(x_data_flow_parents) == 0:
                    # function reference could be resolved, simply return Identifier then:
                    result.append(x)
                else:
                    raise AssertionError(f"Identifier '{x.attributes['name']}' has >1 data flow parent, "
                                         f"even though functions may not be declared twice")

                # function foo(x,y,z) {}
                # chrome.runtime.onMessage.addListener(foo);
                #
                # [1] [Program] (2 children)
                # 	[2] [FunctionDeclaration] (5 children) --e--> [7]             <-----
                # 		[3] [Identifier:"foo"] (0 children) --data--> [17]        <-----
                # 		[4] [Identifier:"x"] (0 children)
                # 		[5] [Identifier:"y"] (0 children)
                # 		[6] [Identifier:"z"] (0 children)
                # 		[7] [BlockStatement] (0 children)
                # 	[8] [ExpressionStatement] (1 child)
                # 		[9] [CallExpression] (2 children)
                # 			[10] [MemberExpression] (2 children)
                # 				[11] [MemberExpression] (2 children)
                # 					[12] [MemberExpression] (2 children)
                # 						[13] [Identifier:"chrome"] (0 children)
                # 						[14] [Identifier:"runtime"] (0 children)
                # 					[15] [Identifier:"onMessage"] (0 children)
                # 				[16] [Identifier:"addListener"] (0 children)
                # 			[17] [Identifier:"foo"] (0 children)                  <-----

            else:
                result.append(x)

        # If len(pattern_match.children) < 2, we have a "chrome.runtime.onMessage.addListener()" call, i.e., the
        #   argument is missing!

    return result


class DataFlow:
    def __init__(self, nodes):
        self.nodes = nodes

    def __str__(self):
        return " -> ".join(f"[{node.id}]" for node in self.nodes)

    def pretty(self):  # => result is used later by json.dump()
        return [{
            "no": i+1,
            "location": self.nodes[i].get_location(),
            "filename": self.nodes[i].get_file(),
            "identifier": self.nodes[i].attributes['name']\
                            if 'name' in self.nodes[i].attributes else f"<{self.nodes[i].name}>",
            "line_of_code": self.nodes[i].get_whole_line_of_code_as_string()
        } for i in range(len(self.nodes))]

    @classmethod
    def from_node_list(cls, node_list):
        return DataFlow(node_list)

    @classmethod
    def beginning_at(cls, initial_node):
        if not initial_node.name == "Identifier":
            raise TypeError(f"A data flow must begin at an Identifier, not a(n) {initial_node.name}")
        return DataFlow([initial_node])

    def may_continue(self):
        """
        Returns True iff this data flow may be continued.
        """
        return len(self.nodes[-1].data_dep_children) > 0

    def continue_flow(self):
        """
        Returns a list of all possible (1-step) continuations of this DataFlow (being DataFlows themselves),
        or `None` if this DataFlow cannot be continued any further.
        """
        result = []
        next = self.nodes[-1].data_dep_children
        if len(next) == 0:
            return None  # indicate that this DataFlow cannot be continued any further
        for child_data_dep in next:
            result.append(DataFlow.from_node_list(self.nodes + [child_data_dep.extremity]))
        return result

    def get_all_continued_flows(self):
        """
        Returns a list of all possible (n-step) continuations of this DataFlow (being DataFlows themselves).
        Because of repeated branching, the list returned can, in theory, be arbitrarily long.
        Returns `[self]` if this DataFlow cannot be continued any further.
        """
        data_flows = [self]  # may remain a list of 1 item if there's just 1 flow, may split up
        while any(df.may_continue() and not df.has_cycle() for df in data_flows):
            df_to_continue_index = next(i for i in range(len(data_flows)) if data_flows[i].may_continue()
                                                                          and not data_flows[i].has_cycle())
            df_to_continue = data_flows[df_to_continue_index]
            # Continue data flow, might result in a split into multiple new data flows:
            continued_flow = df_to_continue.continue_flow()  # (not None because df_to_continue.may_continue())
            data_flows = data_flows[:df_to_continue_index] + continued_flow + data_flows[df_to_continue_index + 1:]
        return data_flows
        # Note that the code above seems a bit ugly, but we need to *replace* each data flow once continued!

    def last_node(self):
        return self.nodes[-1]

    def get_sub_flow(self, first_node=None, last_node=None):
        """
        Returns this DataFlow but
        (a) starting only at the given `first_node` (inclusive),
        (b) cut off after the given `last_node` (inclusive).
        """
        if first_node is None and last_node is None:
            return self
        elif first_node is None:
            return DataFlow(self.nodes[:self.nodes.index(last_node) + 1])
        elif last_node is None:
            return DataFlow(self.nodes[self.nodes.index(first_node):])
        else:
            return DataFlow(self.nodes[self.nodes.index(first_node):self.nodes.index(last_node) + 1])

    def has_cycle(self):
        ids = [node.id for node in self.nodes]
        return len(ids) != len(set(ids))

    def get_accessed_members(self, include_method_calls=False):
        r"""
        Along a data flow, multiple members/attributes of the initial variable may be accessed.
        This function returns a list of all of them, in order (i.e., in the order of the data flow).

        For example:
        ```
        let s = sender;
        let x = s.url;                     // [MemberExpression]
        y = x.replace(/^https:\/\//,"");   // [CallExpression] > [MemberExpression]
        let url_prefix = y.split("/")[0];
        ```

        Then this function returns the following list of strings (when include_method_calls=False):
        ["url"]

        Then this function returns the following list of strings (when include_method_calls=True):
        ["url", "replace", "split"]

        Note: for an access like `s.tab.url`, ["tab", "url"] will be returned!
        """

        # First, some info on what member accesses look like in the PDG:
        #
        # * "x.y":
        #
        # [1] [ExpressionStatement] (1 child)
        # 		[2] [MemberExpression] (2 children)
        # 			[3] [Identifier:"x"] (0 children)
        # 			[4] [Identifier:"y"] (0 children)
        #
        # * "x.y()":
        #
        # [1] [ExpressionStatement] (1 child)
        # 		[2] [CallExpression] (1 child)
        # 			[3] [MemberExpression] (2 children)
        # 				[4] [Identifier:"x"] (0 children)
        # 				[5] [Identifier:"y"] (0 children)
        #
        # * "x.y.z":
        #
        # [1] [ExpressionStatement] (1 child)
        # 		[2] [MemberExpression] (2 children)
        # 			[3] [MemberExpression] (2 children)
        # 				[4] [Identifier:"x"] (0 children)
        # 				[5] [Identifier:"y"] (0 children)
        # 			[6] [Identifier:"z"] (0 children)
        #
        # * "x.y.z()":
        #
        # [1] [ExpressionStatement] (1 child)
        # 		[2] [CallExpression] (1 child)
        # 			[3] [MemberExpression] (2 children)
        # 				[4] [MemberExpression] (2 children)
        # 					[5] [Identifier:"x"] (0 children)
        # 					[6] [Identifier:"y"] (0 children)
        # 				[7] [Identifier:"z"] (0 children)
        #
        # * And now together with a data flow: "a = x.y"
        #
        # [1] [ExpressionStatement] (1 child)
        # 		[2] [AssignmentExpression] (2 children)
        # 			[3] [Identifier:"a"] (0 children)
        # 			[4] [MemberExpression] (2 children)
        # 				[5] [Identifier:"x"] (0 children) --data--> [3]
        # 				[6] [Identifier:"y"] (0 children) --data--> [3]
        #
        # * "a = x.y()":
        #
        # [1] [ExpressionStatement] (1 child)
        # 		[2] [AssignmentExpression] (2 children)
        # 			[3] [Identifier:"a"] (0 children)
        # 			[4] [CallExpression] (1 child)
        # 				[5] [MemberExpression] (2 children)
        # 					[6] [Identifier:"x"] (0 children) --data--> [3]
        # 					[7] [Identifier:"y"] (0 children) --data--> [3]
        #
        # * "a = x.y.z":
        #
        # [1] [ExpressionStatement] (1 child)
        # 		[2] [AssignmentExpression] (2 children)
        # 			[3] [Identifier:"a"] (0 children)
        # 			[4] [MemberExpression] (2 children)
        # 				[5] [MemberExpression] (2 children)
        # 					[6] [Identifier:"x"] (0 children) --data--> [3]
        # 					[7] [Identifier:"y"] (0 children) --data--> [3]
        # 				[8] [Identifier:"z"] (0 children) --data--> [3]
        #
        # * "a = x.y.z()":
        #
        # [1] [ExpressionStatement] (1 child)
        # 		[2] [AssignmentExpression] (2 children)
        # 			[3] [Identifier:"a"] (0 children)
        # 			[4] [CallExpression] (1 child)
        # 				[5] [MemberExpression] (2 children)
        # 					[6] [MemberExpression] (2 children)
        # 						[7] [Identifier:"x"] (0 children) --data--> [3]
        # 						[8] [Identifier:"y"] (0 children) --data--> [3]
        # 					[9] [Identifier:"z"] (0 children) --data--> [3]
        #
        #
        # * "({url: sender_url} = sender)" should be handled in the same way as "sender_url = sender.url" as they're
        #     equivalent; with "({url} = sender)" also being equivalent to "({url: url} = sender)" (same PDG!):
        #
        # [1] [ExpressionStatement] (1 child)
        # 		[2] [AssignmentExpression:"="] (2 children)
        # 			[3] [ObjectPattern] (1 child)
        # 				[4] [Property] (2 children)
        # 					[5] [Identifier:"url"] (0 children)
        # 					[6] [Identifier:"sender_url"] (0 children) --data--> ...
        # 			[7] [Identifier:"sender"] (0 children) --data--> [5] --data--> [6]
        # Data Flow: [7] [Identifier:"sender"] --data--> [6] [Identifier:"sender_url"] --data--> ...

        result = []

        for node in self.nodes:  # For each (Identifier) Node in the DataFlow:
            # If the (Identifier) Node `x` is the left part of a MemberExpression `x.y`
            #     (i.e., a member of it got accessed), add `y` to the list of accessed members inside this DataFlow:
            if node.parent.name == "MemberExpression" and node.is_nth_child_of_parent(0):
                # Skip function calls if include_method_calls=False:
                if (not include_method_calls
                        and node.grandparent() is not None
                        and node.grandparent().name == "CallExpression"
                        and node.parent.is_nth_child_of_parent(0)):  # only skip "x.y()" but not "foo(x.y)" !!!
                    continue
                # Add the name of the accessed member to the result list:
                accessed_member_name: str = node.get_sibling(1).attributes["name"]  # maybe this will raise a KeyError in some cases, we shall see...
                result.append(accessed_member_name)

            # If the (Identifier) Node `x` is part of a `{y: x}` ObjectPattern, add `y` to the list of accessed members
            #     inside this DataFlow:
            elif (node.parent.name == "Property"
                  and node.is_nth_child_of_parent(1)
                  and node.grandparent() is not None
                  and node.grandparent().name == "ObjectPattern"):
                # Add the name of the accessed member to the result list:
                accessed_member_name: str = node.get_sibling(0).attributes["name"]  # maybe this will raise a KeyError in some cases, we shall see...
                result.append(accessed_member_name)

        return result
        # ToDo: handle 2+ member accesses in one expression: "x.y.z" or "x.y.z()"; currently "z" will always be ignored!
        #       => go thru all parents that are "MemberExpression"s in a loop!


class DoubleDataFlow:
    """
    Represents two DataFlows eventually meeting in the same function call.

    Example:
    ```
    "chrome.runtime.onMessage.addListener((msg, sender, sendResponse) => {
        chrome.cookies.getAll({},
            function(cookies) {
                sendResponse(cookies);
            }
        );
        return true;
    });"
    ```
    * 1st flow (from flow/source): cookies      -> cookies
    * 2nd flow (to flow/sink):     sendResponse -> sendResponse
    * function call:               sendResponse(cookies);
    """
    def __init__(self, from_flow, to_flow):
        if from_flow.last_node().parent.id != to_flow.last_node().parent.id or\
                from_flow.last_node().parent.name != "CallExpression":
            raise ValueError("from_flow and to_flow must both end in the same function call/CallExpression")

        self.from_flow = from_flow
        self.to_flow = to_flow
        self.data_flow_number = "?/?"

    def as_pretty_dict(self):
        """
        Returns this DoubleDataFlow as a (JSON-dump-able) dictionary.
        Cf. generated `analysis_renderer_attacker.json` file.
        """
        result = {
            "from_flow": self.from_flow.pretty(),
            "to_flow": self.to_flow.pretty(),
            "function_call": {
                "location": self.from_flow.last_node().parent.get_location(),
                "filename": self.from_flow.last_node().parent.get_file(),
                "line_of_code": self.from_flow.last_node().parent.get_whole_line_of_code_as_string()
            }
        }
        if self.data_flow_number is not None:
            result["data_flow_number"] = self.data_flow_number
        return result

    def __str__(self):
        return json.dumps(self.as_pretty_dict(), indent=4, sort_keys=False, skipkeys=True)


def data_flows_into_function(pdg, from_node, to_node, return_multiple=True):
    """
    Returns the empty list `[]` if no data flow exists from `from_node` to `to_node`.
    Otherwise, returns the data flow(s) from `from_node` to `to_node` as DoubleDataFlow objects.
    Each such DoubleDataFlow consists of:
    * a "from_flow" (from `from_node` to a "CallExpression"), and
    * a "to_flow" (from `to_node` to the *same* "CallExpression").

    Parameters:
        pdg: the entire PDG
        from_node: an Identifier Node of a value containing sensitive data (e.g., cookies)
        to_node: an Identifier Node of a function representing a dangerous sink (e.g., sendResponse)
        return_multiple: a boolean indicating whether to return multiple data flows if multiple data flows exist from
                         the given `from_node` to the given `to_node`; when set to False, the returned list will either
                         be empty or contain exactly 1 element; when set to True, the returned list can have arbitrary
                         length;
                         set to True when you later want to filter the returned data flows, e.g., only for the
                         unprotected/un-checked/un-sanitized ones (!!!)

    Returns:
        Returns the empty list `[]` if no data flow exists from `from_node` to `to_node`.
        Otherwise, returns the data flow(s) from `from_node` to `to_node` as DoubleDataFlow objects.
    """
    if os.environ.get('PRINT_PDGS') == "yes":
        print(f"Looking for data flow in PDG [{pdg.id}] from node [{from_node.id}] to function [{to_node.id}] ...")

    data_flows_from = DataFlow.beginning_at(from_node).get_all_continued_flows()

    data_flows_to = DataFlow.beginning_at(to_node).get_all_continued_flows()

    # Check if any data flow from `data_flows_from` and any data flow from `data_flows_to` end up in the same
    #   CallExpression; if so return both of these data flows:
    results = []
    for from_flow in data_flows_from: # ToDo: what if data flow continues beyond the CallExpression, e.g., when the function's return value is used?!!! => it's not enough to just check each last_node() then!!!
        for to_flow in data_flows_to:
            if from_flow.last_node().parent.id == to_flow.last_node().parent.id and from_flow.last_node().parent.name == "CallExpression":
                result = DoubleDataFlow(from_flow=from_flow,to_flow=to_flow)
                if return_multiple:
                    results.append(result)
                else:
                    result.data_flow_number = f"1/1+"  # meaning: 1st data flow of 1 (or more) total data flows
                    return [result]

    for i in range(len(results)):
        results[i].data_flow_number = f"{i+1}/{len(results)}"

    return results


def expression_correctly_verifies_sender_object(test_expression, sender_object_node):  # ToDo
    """
    Helper function for expression_correctly_verifies_sender().
    Unlike for the `sender_node` of expression_correctly_verifies_sender(), we already know here that the
    `sender_object_node` is *directly* the "sender" object (with .url, .tab.url, .origin, etc. attributes), and not,
    for example, already some attribute/member of it (like sender.url).

    Parameters:
        test_expression: the condition of some if statement; question: Does it correctly *verify* the sender?!
        sender_object_node: the part of the `test_expression` representing the sender
                            (has .url, .tab.url and .origin attributes, among others)

    Returns:
        a boolean, True if the `text_expression` correctly verifies the sender, False otherwise.
    """
    return False


def is_safe_url_prefix(url_prefix):
    """
    E.g., "https://admin.com/" is a safe URL prefix but "https://admin.com" (w/o the trailing slash) isn't!
    "https://" on its own is also an unsafe prefix!
    Note that the prefix doesn't have to end with a slash though, "https://admin.com/foo" is also a safe URL prefix.
    """
    if os.environ.get('CONSIDER_HTTP_AS_SAFE') == "yes":
        return re.fullmatch("^https?://.+/.*$", url_prefix) is not None  # => implicitly checks equality of the origin!
    else:
        return re.fullmatch("^https://.+/.*$", url_prefix) is not None  # => implicitly checks equality of the origin!
    # Checking that the URL has an http:// prefix is still considered an insecure verification of the sender as the
    #   authenticity of such a sender still cannot be guaranteed. A renderer attacker + network attacker would still be
    #   able to exploit the vulnerability in the extension!
    # This default behavior is only deactivated when the user supplies the --consider-http-as-safe argument.


def is_safe_origin_suffix(origin_suffix):
    """
    E.g., ".admin.com" and ".admin.co.uk" are safe origin suffixes but "admin.com" and ".co.uk" aren't!
    "/admin.com", "//admin.com", "://admin.com" and "https://admin.com" can also be considered safe suffixes
    (but not "http://admin.com", see below).

    Note that by using Mozilla's Public Suffix List (PSL) (https://publicsuffix.org/), we can identify a danger even
    when the code checks for a suffix like ".blogspot.com" for example!

    Note that even a triple-suffix like ".sth.ac.at" can be available for public registration and hence unsafe!
    """
    if "http://" in origin_suffix:
        # The origin is essentially checked to be equal to a http:// domain, this means that the entire origin check
        #   is essentially pointless though, since all HTTP communication can be manipulated anyways.
        return False
    elif "/" in origin_suffix:
        # As the sender.origin will never contain a slash except for the one from "https://",
        #   if there's a "/" in the origin suffix check, this always means there's essentially a check on the entire
        #   origin!
        return True
    elif "." not in origin_suffix:
        return False  # e.g. simply suffix check for "com" => not even REMOTELY sufficient!
    else:  # e.g. ".admin.co.uk" or ".admin.com" or "foo.admin.com" (all good) or "admin.co.uk" or "admin.com" (all bad)
        actually_verified_suffix = origin_suffix[origin_suffix.index(".")+1:]  # only everything after the first "." is actually verified
        extract = tldextract.TLDExtract()
        return extract(actually_verified_suffix, include_psl_private_domains=True).domain != ''


def expression_correctly_verifies_sender_url(test_expression, sender_url_node):
    """
    Helper function for expression_correctly_verifies_sender().

    Examples of correct sender URL verifications:
    * url == "https://admin.com/"
    * url === "https://admin.com/"
    * url.startsWith("https://admin.com/")
    * ["option1", "option2"].includes(url)
    * url == "option1" | url == "option2"
    * url === "option1" || url === "option2"

    All of the above may be contained in a more complicated conjunction using "&" or "&&":
    * (url == "https://admin.com/" & something_else())
    * (url == "https://admin.com/" && something_else())

    Parameters:
        test_expression: the condition of some if statement; question: Does it correctly *verify* the sender (URL)?!
        sender_url_node: the part of the `test_expression` representing the sender URL

    Returns:
        a boolean, True if the `text_expression` correctly verifies the sender URL, False otherwise.
    """
    if not sender_url_node.lies_within(test_expression)\
            and not any(identifier.is_data_flow_equivalent_identifier(sender_url_node)
                        for identifier in test_expression.get_all_identifiers()):
        # `test_expression` cannot verify `sender_url_node` if `test_expression` does not *contain* `sender_url_node`
        #     (or at least a "data-flow-equivalent" node, take "url == 'foo' || url == 'foo'" for example where both
        #     "url" identifiers are deemed "data-flow-equivalent")
        return False

    elif test_expression.name == "BinaryExpression" and test_expression.attributes['operator'] in ["==", "==="]:
        left_operand = test_expression.children[0]
        right_operand = test_expression.children[1]
        if left_operand.equivalent(right_operand):
            return False  # "url == url" or "url === url" is trivially True and therefore *not* a sufficient check!
        elif sender_url_node.lies_within(left_operand) and sender_url_node.lies_within(right_operand):
            # Something like, maybe, "url == url.toLowerCase()", or "url == url.substring(0,30)",
            # or "url.length == url.substring(20,22)"
            # => all unsafe checks
            # Something like, maybe, "url == 'foo' + url" would always be False and therefore *THEORETICALLY* be a
            # good enough "protection" for a block of code. However, (a) it seems unlikely that someone would write
            # such an always-False "check" and (b) even *if*, we simply return it as a vulnerability, leaving some
            # manual verification effort for the human (as always).
            return False
        elif os.environ.get('CONSIDER_HTTP_AS_SAFE') != "yes" and\
                (left_operand.any_string_literal_inside_matches_full_regex(r"http:\/\/.*") or
                 right_operand.any_string_literal_inside_matches_full_regex(r"http:\/\/.*")):
            return False  # return False for "url == 'http://...'" as HTTP is unsafe!!! (renderer + network attacker)
        else:
            return True  # We assume "url == ...", "... == url", "url === ..." or "... === url" to be valid checks!

    # "url == "https://admin.com/" && something_else()"  (ONE side of the "&&" needs to verify the URL!):
    elif test_expression.name == "LogicalExpression" and test_expression.attributes['operator'] == "&&"\
            or test_expression.name == "BinaryExpression" and test_expression.attributes['operator'] == "&":
        left_operand = test_expression.children[0]
        right_operand = test_expression.children[1]
        left_operand_correctly_verifies_sender_url =\
            expression_correctly_verifies_sender_url(test_expression=left_operand, sender_url_node=sender_url_node)
        right_operand_correctly_verifies_sender_url = \
            expression_correctly_verifies_sender_url(test_expression=right_operand, sender_url_node=sender_url_node)
        return left_operand_correctly_verifies_sender_url or right_operand_correctly_verifies_sender_url

    # "url == "option1" || url == "option2"" (BOTH sides of the "||" need to verify the URL!):
    elif test_expression.name == "LogicalExpression" and test_expression.attributes['operator'] == "||"\
            or test_expression.name == "BinaryExpression" and test_expression.attributes['operator'] == "|":
        left_operand = test_expression.children[0]
        right_operand = test_expression.children[1]
        left_operand_correctly_verifies_sender_url = \
            expression_correctly_verifies_sender_url(test_expression=left_operand, sender_url_node=sender_url_node)
        right_operand_correctly_verifies_sender_url = \
            expression_correctly_verifies_sender_url(test_expression=right_operand, sender_url_node=sender_url_node)
        return left_operand_correctly_verifies_sender_url and right_operand_correctly_verifies_sender_url

    # "url.startsWith("https://admin.com/")" (URL needs to end with a '/' that's *not* the slash from 'https://'!):
    #     [1] [CallExpression] (2 children)
    #         [2] [MemberExpression] (2 children)
    #             [3] [Identifier:"url"] (0 children)            == sender_url_node
    #             [4] [Identifier:"startsWith"] (0 children)
    #         [5] [Literal:""https://admin.com/""] (0 children)
    elif test_expression.name == "CallExpression"\
            and len(test_expression.children) == 2\
            and test_expression.children[0].name == "MemberExpression"\
            and len(test_expression.children[0].children) == 2\
            and test_expression.children[0].children[0] == sender_url_node\
            and test_expression.children[0].children[1].name == "Identifier"\
            and test_expression.children[0].children[1].attributes['name'] == "startsWith"\
            and test_expression.children[1].name == "Literal"\
            and is_safe_url_prefix(test_expression.children[1].string_literal_strip_quotation_marks()):
        return True

    # "["option1", "option2"].includes(url)":
    # [1] [CallExpression] (2 children)
    #     [2] [MemberExpression] (2 children)
    #         [3] [ArrayExpression] (2 children)
    #             [4] [Literal:""option1""] (0 children)
    #             [5] [Literal:""option2""] (0 children)
    #         [6] [Identifier:"includes"] (0 children)
    #     [7] [Identifier:"url"] (0 children)             == sender_url_node
    elif test_expression.name == "CallExpression"\
            and len(test_expression.children) == 2\
            and test_expression.children[0].name == "MemberExpression"\
            and len(test_expression.children[0].children) == 2\
            and test_expression.children[0].children[0].name == "ArrayExpression"\
            and test_expression.children[0].children[1].name == "Identifier"\
            and test_expression.children[0].children[1].attributes['name'] == "includes"\
            and test_expression.children[1] == sender_url_node:
        return True

    else:
        return False

    # ToDo: handle UnaryExpression with '!' operator!!!


def expression_correctly_verifies_sender_origin(test_expression, sender_origin_node): # ToDo
    """
    Helper function for expression_correctly_verifies_sender().

    Examples of correct sender origin verifications:
    * origin == "https://admin.com"
    * origin === "https://admin.com"
    * origin.endsWith(".admin.com")
    * origin.endsWith(".admin.co.uk")
    * origin.endsWith("/admin.com")
    * ["option1", "option2"].includes(origin)

    All of the above may be contained in a more complicated conjunction using "&" or "&&":
    * (origin == "https://admin.com" & something_else())
    * (origin == "https://admin.com" && something_else())

    Parameters:
        test_expression: the condition of some if statement; question: Does it correctly *verify* the sender (origin)?!
        sender_origin_node:

    Returns:
        a boolean, True if the `text_expression` correctly verifies the sender origin, False otherwise.
    """
    return False


def expression_correctly_verifies_sender(test_expression, sender_node, data_flow):
    """
    Helper function for verifies_sender_is_safe().
    Note that it is assumed that `sender_node.lies_within(test_expression)`!
    It is also assumed that `sender_node in data_flow.nodes`!

    Note that the sender_node may be:
    (1) simply the `sender` variable from `(msg, sender, sendResponse)`
    (2) a renamed alias of it, e.g.: `let from = sender;`
    (3) a variable storing a property of the sender, e.g.: `let url = sender.url;`
    (4)                                       ...but also: `let len = sender.url.length;`
                                                       or: `let active = sender.tab.active;` (which is simply a boolean)
    (5) some more advanced computation on one of the sender's attributes, e.g.: `sender.url.replace(...)`

    Parameters:
        test_expression: the expression to check: Does it correctly *verify* the sender?!
        sender_node: the PDG node having a data flow from `sender` into it *and* lying within `test_expression`
        data_flow: the complete data from `sender` that `sender_node` is a part of

    Returns:
        a boolean indicating whether `test_expression` correctly verifies the sender
    """
    assert sender_node.lies_within(test_expression)
    assert sender_node in data_flow.nodes

    data_flow = data_flow.get_sub_flow(last_node=sender_node)
    accessed_members = data_flow.get_accessed_members(include_method_calls=False)
    if accessed_members == []:  # case (1) or (2): sender_node is still simply the sender object
        return expression_correctly_verifies_sender_object(test_expression=test_expression, sender_object_node=sender_node)
    elif accessed_members == ["url"] or accessed_members == ["tab", "url"]:  # case (3): sender_node === sender.url or sender.tab.url
        return expression_correctly_verifies_sender_url(test_expression=test_expression, sender_url_node=sender_node)
    elif accessed_members == ["origin"]:  # case (3): sender_node === sender.origin
        return expression_correctly_verifies_sender_origin(test_expression=test_expression, sender_origin_node=sender_node)
    else:
        # case (4): some other property of sender that is not useful as a safety check is used in the test_expression
        # case (5): some more advanced computation on one of the sender's attributes, e.g.: `sender.url.replace(...)`
        # Note that while this *might* still be a correct sender verification, we are in doubt and still return the
        #   vulnerability, leaving it to the human to verify the vulnerability!
        return False


def verifies_sender_is_safe(pdg, test_expression, sender_identifier):
    """
    Returns True if the `test_expression` Expression Node *correctly* verifies the safety of the sender stored in
    `sender_identifier`.

    Examples of correct sender verifications:
    * sender.url == "https://admin.com/"
    * sender.url === "https://admin.com/"
    * sender.origin == "https://admin.com"
    * sender.origin === "https://admin.com"
    * sender.url.startsWith("https://admin.com/")
    * sender.origin.endsWith(".admin.com")
    * ["option1", "option2"].includes(sender.url)
    * ["option1", "option2"].includes(sender.origin)

    All of the above may be contained in a more complicated conjunction using "&" or "&&":
    * (sender.url == "https://admin.com/" & something_else())
    * (sender.url == "https://admin.com/" && something_else())

    Also, the sender URL/origin might have been written into another intermediary variable first:
    ```
    let url = sender.url;
    if (url == "https://admin.com/") {
        /* ... */
    }
    ```

    Also note that "sender.tab.url" may be used instead of "sender.url" as well!

    (!!!) The `test_expression` evaluating to TRUE must IMPLY that the sender is safe. (!!!)

    (!!!) The if-branch of the if-statement is safe. (!!!)
    """
    sender_identifier_data_flows = DataFlow.beginning_at(sender_identifier).get_all_continued_flows()
    # For each data flow sender -> ... -> ... -> ...:
    for sender_identifier_data_flow in sender_identifier_data_flows:
        if os.environ.get('PRINT_PDGS') == "yes":                      #
            print(f"Sender data flow: {sender_identifier_data_flow}")  #

        # For each node in such a data flow: sender -> ... -> ... -> ...:
        #                                    |____|    |_|    |_|    |_|
        for sender_node in sender_identifier_data_flow.nodes:

            # If this node lies within the test expression of which we want to check whether it verifies sender safety:
            if sender_node.lies_within(test_expression):
                if os.environ.get('PRINT_PDGS') == "yes":                                                 #
                    print(f"\t=> [{sender_node.id}] lies within test expression [{test_expression.id}]")  #

                # Check if the `test_expression` *correctly* verifies the safety of the sender represented by `sender_node`:
                if expression_correctly_verifies_sender(test_expression, sender_node, sender_identifier_data_flow):
                    print(f"Found correct sender verification in {test_expression.get_file()}, "
                          f"line {test_expression.get_line()}: {test_expression.get_whole_line_of_code_as_string()}")
                    return True
                # Note that the sender may occur more than once inside the `test_expression`, e.g.:
                #     if (sender && sender.url == "https://admin.com/") { /* ... */ }
                #     if (sender.url.length > 18 && sender.url.startsWith("https://admin.com/")) {/ *...* /}
                # => Therefore, we cannot simply return False when expression_correctly_verifies_sender() returns False!

    # Either no flow from `sender_identifier` into the `test_expression` could be found,
    # or the `test_expression` did not correctly verify the `sender_identifier`:
    return False


def verifies_sender_is_unsafe(pdg, test_expression, sender_identifier): # ToDo
    """
    Note that this function does *not* simply return the opposite of the verifies_sender_is_safe() function!
    A test expression may neither verify safety *nor* non-safety of the sender, e.g., when it doesn't perform a check on
    the sender at all, doing something completely unrelated, or, when it performs in incorrect/incomplete check of the
    sender!

    Also note that a sender un-safety check may be combined with other checks in a DISJUNCTION ("|" or "||" operator)
    but NOT in a CONJUNCTION ("&" or "&&" operator), i.e., the exact opposite of the verifies_sender_is_safe() function!
    Think of it as swapping the "if" and "else" branches / negating the condition. Example:
    * (sender.url != "https://admin.com/" | something_else())
    * (sender.url != "https://admin.com/" || something_else())

    (!!!) The sender being unsafe must IMPLY that the `test_expression` evaluates to TRUE. (!!!)

    (!!!) The else-branch of the if-statement is safe. (!!!)
    """
    pass


def get_protected_blocks_of_code(pdg, pdg_subtree, sender_identifier):
    """
    Returns all blocks of code inside the given `pdg_subtree` where the sender identifier (given as the second argument)
    is *correctly* verified.

    There are 3 different ways of sender URL/origin verification that we consider to be "correct":
    (1) checking the URL (either sender.url or sender.tab.url) or origin (sender.origin) for equality using "==" or
        "===" or using an Array.includes() call (except when checking for trivial equality to itself of course)
    (2) checking a URL prefix, prefix must contain a slash "/" other than the two slashes from "://", this ensures that
        there's an (implicit) equality check for the origin
    (3) checking the suffix of origin, such that there's an (implicit) equality check of the domain name,
        e.g., ".admin.com" or ".admin.co.uk" but not "admin.com" or ".co.uk" (!!!)

    Some examples of correct sender verifications are:
    * sender.url == "https://admin.com/"
    * sender.url === "https://admin.com/"
    * sender.origin == "https://admin.com"
    * sender.origin === "https://admin.com"
    * sender.url.startsWith("https://admin.com/")
    * sender.origin.endsWith(".admin.com")
    * ["option1", "option2"].includes(sender.url)
    * ["option1", "option2"].includes(sender.origin)

    Some examples of *incorrect* sender verifications are:
    * sender.url == sender.url
    * sender.url === sender.url
    * sender.origin == sender.origin
    * sender.origin === sender.origin
    * sender.url != "https://bad.com/"
    * sender.url !== "https://bad.com/"
    * sender.url.startsWith("https://admin.com")    sender.origin.startsWith("https://admin.com")
    * sender.url.includes("admin.com")              sender.origin.includes("admin.com")
    * sender.url.endsWith("admin.html")             sender.origin.endsWith("admin.com")
    * sender.url.endsWith(".admin.com/")            sender.origin.endsWith(".co.uk")
    * ["option1", "option2", sender.url].includes(sender.url)
    * ["option1", "option2", sender.origin].includes(sender.origin)

    Note that, instead of sender.url, sender.tab.url may be also used (extension requires the "tabs" permission though).

    Also note that sender.url, sender.tab.url or sender.origin might also flow into another variable before being
    checked!
    """
    protected_blocks_of_code = []

    all_if_statements_inside_pdg_subtree = pdg_subtree.get_all_if_statements_inside()
    for if_statement in all_if_statements_inside_pdg_subtree:
        if_condition = if_statement.children[0]
        if_block = if_statement.children[1]
        else_block = if_statement.children[2] if len(if_statement.children) > 2 else None
        # The else_block could be another IfStatement, in that case it will *also* be enumerated by
        #     get_all_if_statements_inside().

        if verifies_sender_is_safe(test_expression=if_condition, sender_identifier=sender_identifier, pdg=pdg):
            protected_blocks_of_code.append(if_block)
        if verifies_sender_is_unsafe(test_expression=if_condition, sender_identifier=sender_identifier, pdg=pdg) and\
                else_block is not None:
            protected_blocks_of_code.append(else_block)

        # Note how this even catches the following case:
        #
        # if (sender.url != "safe.com") {
        #     /* ... */
        # } else if (something_completely_unrelated()) {
        #     /* PROTECTED BLOCK OF CODE */
        #     sendResponse(cookies);
        # }

    return protected_blocks_of_code


def get_explicitly_unsafe_blocks_of_code(pdg, pdg_subtree, sender_identifier):
    """
    Cf. get_protected_blocks_of_code() but returns all blocks of code where it has been explicitly verified that the
    sender is *not* safe!
    """
    explicitly_unsafe_blocks_of_code = []

    all_if_statements_inside_pdg_subtree = pdg_subtree.get_all_if_statements_inside()
    for if_statement in all_if_statements_inside_pdg_subtree:
        if_condition = if_statement.children[0]
        if_block = if_statement.children[1]
        else_block = if_statement.children[2] if len(if_statement.children) > 2 else None

        if verifies_sender_is_safe(test_expression=if_condition, sender_identifier=sender_identifier, pdg=pdg) and \
                else_block is not None:
            explicitly_unsafe_blocks_of_code.append(else_block)
        if verifies_sender_is_unsafe(test_expression=if_condition, sender_identifier=sender_identifier, pdg=pdg):
            explicitly_unsafe_blocks_of_code.append(if_block)

    return explicitly_unsafe_blocks_of_code


def detect_41_31_vuln_in_bp(pdg_bp, results, benchmarks, uxss=False):  # ToDo: handle uxss=True
    """
    Look for type 4.1 vulnerabilities in the given background page/service worker (or rather its PDG), type 4.1
    vulnerabilities refer to the ability to `Execute Privileged Browser APIs` w/o (sufficiently) verifying `sender.url`,
    which is a security violation of type 3.1: `Extension Message Authentication`
    (refer to Kim and Lee paper for more info)

    Example vulnerability (with no authentication of `sender.url` or `sender.tab.url` or `sender.origin` whatsoever):
    ```
    chrome.runtime.onMessage.addListener((msg, sender, sendResponse) => {
        chrome.cookies.getAll({},
            function(cookies) {
                sendResponse(cookies);
            }
        );
        return true;
    });
    ```
    """
    start = timeit.default_timer()

    cookies_sources = get_all_cookie_identifiers(pdg_bp)
    sendResponse_sinks = get_all_sendResponse_sinks(pdg_bp)

    print(f"[3.1+4.1] No. of cookies sources: {len(cookies_sources)}")
    print(f"[3.1+4.1] No. of sendResponse sinks: {len(sendResponse_sinks)}")

    if os.environ.get('PRINT_PDGS') == "yes":
        # print(f"PDG BP: {pdg_bp}")
        for cookies_source in cookies_sources:
            print(f"cookies source: {cookies_source}")
        for sendResponse_sink in sendResponse_sinks:
            print(f"sendResponse sink: {sendResponse_sink}")

    try:
        for cookies_source in cookies_sources:
            for sendResponse_sink in sendResponse_sinks:
                sender_identifier = sendResponse_sink.get_sibling(1)  # (message, sender, sendResponse)
                pdg_subtree = sendResponse_sink.get_parent(["FunctionExpression", "ArrowFunctionExpression"])

                data_flows = data_flows_into_function(pdg=pdg_bp,
                                                      from_node=cookies_source,
                                                      to_node=sendResponse_sink,
                                                      return_multiple=(os.environ.get('RETURN_MULTIPLE_FLOW_VARIANTS') == "yes" or
                                                                       os.environ.get('RETURN_SAFE_FLOWS_VERIFIED') != "yes"))
                # We need all data flows when there are multiple ones if...:
                # (a) the user specified --return-multiple-flow-variants
                # and/or
                # (b) the check for sender verification is on, i.e., RETURN_SAFE_FLOWS_VERIFIED is OFF(!)
                #
                # In other words:
                # We can *only* refrain from searching for multiple data flow if...:
                # (a) the user did *not* specify --return-multiple-flow-variants
                # *and*
                # (b) the check for sender verification is off, i.e., RETURN_SAFE_FLOWS_VERIFIED is ON
                #     (otherwise we could potentially miss an unsafe flow if we only look for 1 flow and that one just
                #      happens to be a safe one!)

                for data_flow in data_flows:
                    sink_call = data_flow.from_flow.last_node().parent  # the final dangerous CallExpression
                    assert sink_call.name == "CallExpression"

                    # Logic:

                    # if any node in data_flow lies_within any protected_block_of_code:
                    #    safe
                    # elif is there a return statement before the sink call and that return statement lies_within an
                    #      explicitly_dangerous_part_of_code and the if statement it's in is on the same depth as the sink call?:
                    #    safe
                    # else:
                    #    unsafe

                    if any(any(node.lies_within(protected_block_of_code)
                                for protected_block_of_code in get_protected_blocks_of_code(pdg=pdg_bp,
                                                                                            pdg_subtree=pdg_subtree,
                                                                                            sender_identifier=sender_identifier))
                                for node in data_flow.from_flow.nodes + data_flow.to_flow.nodes):
                        # safe; return only if --return-safe-flows-verified has been set:
                        if os.environ.get('RETURN_SAFE_FLOWS_VERIFIED') == "yes":
                            print(f"[4.1/3.1] Safe data flow found:\n{str(data_flow)}\n")
                            results.append(data_flow.as_pretty_dict())
                            if os.environ.get('RETURN_MULTIPLE_FLOW_VARIANTS') != "yes":
                                raise StopIteration

                    elif any(any(return_statement.lies_within(explicitly_unsafe_block_of_code)
                                 and return_statement.occurs_in_code_before(sink_call)
                                 and return_statement.get_innermost_surrounding_if_statement().is_sibling_of(sink_call)
                                 for explicitly_unsafe_block_of_code in get_explicitly_unsafe_blocks_of_code(pdg=pdg_bp,
                                                                                                             pdg_subtree=pdg_subtree,
                                                                                                             sender_identifier=sender_identifier))
                                 for return_statement in pdg_bp.get_all_return_statements_inside()):
                        # safe; return only if --return-safe-flows-verified has been set:
                        if os.environ.get('RETURN_SAFE_FLOWS_VERIFIED') == "yes":
                            print(f"[4.1/3.1] Safe data flow found:\n{str(data_flow)}\n")
                            results.append(data_flow.as_pretty_dict())
                            if os.environ.get('RETURN_MULTIPLE_FLOW_VARIANTS') != "yes":
                                raise StopIteration

                        # Catches:
                        #
                        # if (sender.url != "safe.com") { // explicitly_unsafe_block_of_code
                        #     return; // return_statement // explicitly_unsafe_block_of_code
                        # }                               // explicitly_unsafe_block_of_code
                        # sendResponse(cookies); // sink_call
                        #
                        # But not:
                        #
                        # if (sender.url != "safe.com") {      // explicitly_unsafe_block_of_code
                        #     if (1==2) {                      // explicitly_unsafe_block_of_code
                        #          return; // return_statement // explicitly_unsafe_block_of_code
                        #     }                                // explicitly_unsafe_block_of_code
                        # }                                    // explicitly_unsafe_block_of_code
                        # sendResponse(cookies); // sink_call
                        #
                        # And also not:
                        #
                        # if (1==1) {
                        #     /* ... */
                        # } else {
                        #     if (sender.url != "safe.com") { // explicitly_unsafe_block_of_code
                        #         return; // return_statement // explicitly_unsafe_block_of_code
                        #     }                               // explicitly_unsafe_block_of_code
                        # }
                        # sendResponse(cookies); // sink_call

                    else:
                        # unsafe
                        print(f"[4.1/3.1] Data flow found:\n{str(data_flow)}\n")
                        results.append(data_flow.as_pretty_dict())
                        if os.environ.get('RETURN_MULTIPLE_FLOW_VARIANTS') != "yes":
                            raise StopIteration
    except StopIteration:
        pass

    time_diff = timeit.default_timer() - start
    print(f'Successfully analyzed BP for 4.1/3.1 vulnerabilities in {time_diff}s')
    benchmarks[f"bp: 4.1/3.1 vulnerabilities{' (UXSS)' if uxss else ''}"] = time_diff


def detect_31_vuln_in_bp(pdg_bp, results, benchmarks):
    """
    Detects all violations of Kim and Lee's Security Requirement 3.1 (Extension Message Authentication),
    for which there is **NO** type 4.1 vulnerability (Execution of Privileged Browser APIs).

    An example of this would be the "Cisco Webex Extension" that violates Sec. Req. 3.1 by not authenticating
    incoming extension messages, however only resulting in the "Start Cisco Webex Meetings application", i.e.,
    something relatively harmless, no sensitive data exfiltration, no UXSS vector (cf. detect_41_31_vuln_in_bp()):

    ```
    chrome.runtime.onMessage.addListener(function(e, n) {
        if (console.log("[Background] onMessage:", e.ext_message_type), a.doiReady) {
            var o = {
                category: "browser-extension",
                event: "launch-meeting",
                extVal: e
            };
            doi.send("Event", o, !0)
        }
    })
    ```
    (code from the Cisco WebEx Extension, version 1.17.0)

    This function shall only be executed when the user supplies the
        --include-31-violations-without-privileged-api-access
    command line argument.
    """
    start = timeit.default_timer()

    all_msg_listeners = get_all_message_listeners(pdg_bp, resolve_function_references=True)
    print(f"[3.1, no 4.1] {len(all_msg_listeners)} message listeners found in total (in BP).")
    for msg_listener in all_msg_listeners:
        print(f"[3.1, no 4.1] Looking at message listener in line {msg_listener.get_line()} in file "
              f"'{msg_listener.get_file()}'...")
        if msg_listener.name == "FunctionExpression":
            # [1] [FunctionExpression] (4 children)
            #     [2] [Identifier:"msg"] (0 children)
            #     [3] [Identifier:"sender"] (0 children)        <----- children[1]
            #     [4] [Identifier:"sendResponse"] (0 children)
            #     [5] [BlockStatement] (0 children)             <-----
            block_of_code = msg_listener.get_child("BlockStatement")
            sender_identifier = None if len(msg_listener.children) < 3 else msg_listener.children[1]
        elif msg_listener.name == "ArrowFunctionExpression":
            # [1] [ArrowFunctionExpression] (4 children)
            #     [2] [Identifier:"msg"] (0 children)
            #     [3] [Identifier:"sender"] (0 children)        <----- children[1]
            #     [4] [Identifier:"sendResponse"] (0 children)
            #     [5] [BlockStatement] (0 children)             <-----
            block_of_code = msg_listener.get_child("BlockStatement")
            sender_identifier = None if len(msg_listener.children) < 3 else msg_listener.children[1]
        elif msg_listener.name == "FunctionDeclaration":
            # [1] [FunctionDeclaration] (5 children) --e--> [6]
            # 		[2] [Identifier:"foo"] (0 children) --data--> [...]
            # 		[3] [Identifier:"msg"] (0 children)
            # 		[4] [Identifier:"sender"] (0 children)               <----- children[2]
            # 		[5] [Identifier:"sendResponse"] (0 children)
            # 		[6] [BlockStatement] (0 children)                    <-----
            block_of_code = msg_listener.get_child("BlockStatement")
            sender_identifier = None if len(msg_listener.children) < 4 else msg_listener.children[2]
        elif msg_listener.name == "Identifier":
            print(f"[3.1, no 4.1] [Warning] message listener function reference '{msg_listener.attributes['name']}' "
                  f"in line {msg_listener.get_line()}, file '{msg_listener.get_file()}', could not be resolved, "
                  f"likely missing something...")
            continue
        else:
            print(f"[3.1, no 4.1] [Warning] Unexpected Node type of message listener: {msg_listener.name}, "
                  f"likely missing something...")
            continue

        # print(f"[3.1, no 4.1] block_of_code = {block_of_code}")
        # print(f"[3.1, no 4.1] sender_identifier = {sender_identifier}")

        # For each block of code inside a message listener, add it to the result set, if:
        #     (a) the block contains no sensitive API access whatsoever
        #     (b) the block contains no (correct) sender verification whatsoever

        sensitive_apis = block_of_code.get_sensitive_apis_accessed()
        print(f"[3.1, no 4.1] {len(sensitive_apis)} sensitive APIs found.")

        protected_blocks_of_code = [] if sender_identifier is None else\
                                            get_protected_blocks_of_code(pdg=pdg_bp,
                                                                         pdg_subtree=block_of_code,
                                                                         sender_identifier=sender_identifier)
        print(f"[3.1, no 4.1] {len(protected_blocks_of_code)} protected blocks of code found.")

        explicitly_unsafe_blocks_of_code = [] if sender_identifier is None else\
                                            get_explicitly_unsafe_blocks_of_code(pdg=pdg_bp,
                                                                                 pdg_subtree=block_of_code,
                                                                                 sender_identifier=sender_identifier)
        print(f"[3.1, no 4.1] {len(explicitly_unsafe_blocks_of_code)} explicitly unsafe blocks of code found.")

        # --include-31-violations-without-privileged-api-access help text:
        #     Include violations of Security Requirement 3.1 (Extension Message Authentication),
        #         even when no privileged API (like chrome.cookies, chrome.scripting or indexedDB)
        #         is accessed (4.1).
        if (len(sensitive_apis) == 0  # no 4.1 vulnerability...
                and len(protected_blocks_of_code) == 0  # ...but still a 3.1 security requirement violation.
                and len(explicitly_unsafe_blocks_of_code) == 0):
            results.append({
                "msg_listener": {
                    "location": msg_listener.get_location(),
                    "filename": msg_listener.get_file(),
                    "line_of_code": msg_listener.get_whole_line_of_code_as_string()
                },
                "block_of_code": {
                    "location": block_of_code.get_location(),
                    "filename": block_of_code.get_file(),
                    "line_of_code": block_of_code.get_whole_line_of_code_as_string()
                }
            })

    time_diff = timeit.default_timer() - start
    print(f'Successfully analyzed BP for 3.1 violations w/o privileged API access in {time_diff}s')
    benchmarks[f"bp: 3.1 violations w/o privileged API access"] = time_diff
